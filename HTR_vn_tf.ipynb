{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTR_vn_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk7G51gSSXMN8xHYnUH3IJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrijithBalachander/Vietnamese_HTR/blob/main/HTR_vn_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vietnamese HTR"
      ],
      "metadata": {
        "id": "WCGVSPUA-7GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWVP5ZTdq9MM",
        "outputId": "d167c9c4-fa57-41ea-e038-b0d605d855b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing from Kaggle\n",
        "\n",
        "Skip if previously done"
      ],
      "metadata": {
        "id": "PSEo4nQuZFCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "JjKlCtZlTwS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "id": "AMmonHr2T5AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bomaich/vietnamese-handwritten-ocr"
      ],
      "metadata": {
        "id": "dsRMJ3IoucGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir vietnamese_handwritten_ocr\n",
        "!unzip -q vietnamese-handwritten-ocr.zip -d vietnamese_handwritten_ocr/"
      ],
      "metadata": {
        "id": "ra9jigLDuesk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls vietnamese_handwritten_ocr/"
      ],
      "metadata": {
        "id": "q_wPhR5SuidK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "VdcN9Fogui2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing packages"
      ],
      "metadata": {
        "id": "2JcDJcjXeVfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv"
      ],
      "metadata": {
        "id": "TgO52vAitnA_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import re"
      ],
      "metadata": {
        "id": "p46miJo3tnmZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import time\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold, cross_val_score, KFold,StratifiedKFold "
      ],
      "metadata": {
        "id": "fzAbFs_MtpFn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "8J0A6L6GYSqH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Data from Drive for processing\n",
        "\n",
        "Copying processed VNonDB word dataset from drive for further processing into train, valid and test data. The VNonDB word dataset was originally in INKML format which has been converted to corresponding image and label files."
      ],
      "metadata": {
        "id": "39ndOPXZLNDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cp \"/content/drive/MyDrive/InkData_word_processed_resized.zip\" .\n",
        "%cp \"/content/drive/MyDrive/InkData_word_labels.zip\" ."
      ],
      "metadata": {
        "id": "raU0q9nbnmMK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/test_set.txt\n",
        "!wget https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/validation_set.txt\n",
        "!wget https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/train_set.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA_48DeHNc-5",
        "outputId": "981652a3-1695-4826-a5b3-136643095340"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-09 20:48:00--  https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/test_set.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1783 (1.7K) [text/plain]\n",
            "Saving to: ‘test_set.txt’\n",
            "\n",
            "test_set.txt        100%[===================>]   1.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-09 20:48:00 (12.4 MB/s) - ‘test_set.txt’ saved [1783/1783]\n",
            "\n",
            "--2022-06-09 20:48:01--  https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/validation_set.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1074 (1.0K) [text/plain]\n",
            "Saving to: ‘validation_set.txt’\n",
            "\n",
            "validation_set.txt  100%[===================>]   1.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-09 20:48:01 (60.1 MB/s) - ‘validation_set.txt’ saved [1074/1074]\n",
            "\n",
            "--2022-06-09 20:48:01--  https://raw.githubusercontent.com/SrijithBalachander/Vietnamese_HTR/main/data_split/train_set.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4266 (4.2K) [text/plain]\n",
            "Saving to: ‘train_set.txt’\n",
            "\n",
            "train_set.txt       100%[===================>]   4.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-09 20:48:01 (56.1 MB/s) - ‘train_set.txt’ saved [4266/4266]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install patool\n",
        "# import patoolib"
      ],
      "metadata": {
        "id": "4QkY9nrqMLQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir \"InkData_word_processed/\"\n",
        "# patoolib.extract_archive(\"InkData_word_processed.rar\", outdir=\"InkData_word_processed/\")"
      ],
      "metadata": {
        "id": "BXd94sp-a-H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q InkData_word_processed_resized.zip\n",
        "!unzip -q InkData_word_labels.zip"
      ],
      "metadata": {
        "id": "b4Ss28mgoW7r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split into Train, Valid and Test"
      ],
      "metadata": {
        "id": "Em0YW23bM-v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pil_resize(image):\n",
        "  # image = Image.open(all_paths[file])\n",
        "  # image = np.asarray(image)\n",
        "  # right = 100\n",
        "  # left = 100\n",
        "  # top = 100\n",
        "  # bottom = 100\n",
        "    \n",
        "  width, height = image.size\n",
        "  new_width,new_height = image.size\n",
        "\n",
        "  if width < 128:\n",
        "    new_width = width + (128-width)\n",
        "  if height < 32:\n",
        "    new_height = height + (32-height)\n",
        "\n",
        "  result = Image.new(image.mode, (new_width, new_height), (255))\n",
        "\n",
        "  result.paste(image, ((new_width-width)//2, (new_height-height)//2))\n",
        "\n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "SwwhFkZObj8g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_encoding = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdefghijklmnopqrstuvxyzÀÁÂÔÚÝàáâãèéêìíòóôõùúýĂăĐđĩũƒƠơƯưạẢảẤấẦầẩẫậắằẳẵặẹẻẽếỀềỂểễỆệỉịọỏỐốỒồổỗộớờỞởỡợụỦủứừửữựỳỷỹ'\n",
        "print ('the number of characters:', len(char_encoding))\n",
        "max_len_label = 0\n",
        "\n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, char in enumerate(txt):\n",
        "        try:\n",
        "            dig_lst.append(char_encoding.index(char))\n",
        "        except:\n",
        "            print(char)\n",
        "        \n",
        "    return dig_lst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1tYSu4VtqvN",
        "outputId": "c16599bc-6ede-471d-a65f-abacf5341195"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of characters: 147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "X_valid = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_valid = []\n",
        "y_test = []\n",
        "\n",
        "y_train_enc = []\n",
        "train_input_len = []\n",
        "y_train_len = []\n",
        "y_valid_enc = []\n",
        "valid_input_len = []\n",
        "y_valid_len = []\n",
        "\n",
        "images_path = \"InkData_word_processed_resized\"\n",
        "labels_path = \"InkData_word_labels\"\n",
        "\n",
        "# os.chdir(\"InkData_word_processed_resized\")\n",
        "\n",
        "label_files = os.listdir(labels_path)\n",
        "\n",
        "with open(\"/content/train_set.txt\", \"r\") as file:\n",
        "  for value in file:\n",
        "    value = value.split(\".\")[0]\n",
        "    for filename in label_files:\n",
        "      filename = filename.split(\".\")[0]\n",
        "      if value in filename:\n",
        "        image = cv2.cvtColor(cv2.imread(os.path.join(images_path,filename+\".png\")),cv2.COLOR_BGR2GRAY)\n",
        "        # image = Image.open(os.path.join(images_path,filename[0]+\".png\"))\n",
        "        # image = pil_resize(image)\n",
        "        # image = cv2.resize(image, (128,32))\n",
        "        image = image/255.\n",
        "        image = np.expand_dims(image, axis=2)\n",
        "        X_train.append(image)\n",
        "        with open(os.path.join(labels_path,filename+\".txt\"), \"r\") as label_file:\n",
        "          # print(label_file)\n",
        "          for label in label_file:\n",
        "          # label = label_file[0].strip()\n",
        "            y_train.append(label)\n",
        "            y_train_enc.append(encode_to_labels(label))\n",
        "            y_train_len.append(len(label))\n",
        "            train_input_len.append(31)\n",
        "            max_len_label = max(max_len_label,len(label))\n",
        "\n",
        "with open(\"/content/validation_set.txt\", \"r\") as file:\n",
        "  for value in file:\n",
        "    value = value.split(\".\")[0]\n",
        "    for filename in label_files:\n",
        "      filename = filename.split(\".\")[0]\n",
        "      if value in filename:\n",
        "        image = cv2.cvtColor(cv2.imread(os.path.join(images_path,filename+\".png\")),cv2.COLOR_BGR2GRAY)\n",
        "        # image = Image.open(os.path.join(images_path,filename[0]+\".png\"))\n",
        "        # image = pil_resize(image)\n",
        "        # image = cv2.resize(image, (128,32))\n",
        "        image = image/255.\n",
        "        image = np.expand_dims(image, axis=2)\n",
        "        X_valid.append(image)\n",
        "        with open(os.path.join(labels_path,filename+\".txt\"), \"r\") as label_file:\n",
        "          # print(label_file)\n",
        "          for label in label_file:\n",
        "          # label = label_file[0].strip()\n",
        "            y_valid.append(label)\n",
        "            y_valid_enc.append(encode_to_labels(label))\n",
        "            y_valid_len.append(len(label))\n",
        "            valid_input_len.append(31)\n",
        "            max_len_label = max(max_len_label,len(label))\n",
        "\n",
        "\n",
        "with open(\"/content/test_set.txt\", \"r\") as file:\n",
        "  for value in file:\n",
        "    value = value.split(\".\")[0]\n",
        "    for filename in label_files:\n",
        "      filename = filename.split(\".\")[0]\n",
        "      if value in filename:\n",
        "        image = cv2.cvtColor(cv2.imread(os.path.join(images_path,filename+\".png\")),cv2.COLOR_BGR2GRAY)\n",
        "        # image = Image.open(os.path.join(images_path,filename[0]+\".png\"))\n",
        "        # image = pil_resize(image)\n",
        "        # image = cv2.resize(image, (128,32))\n",
        "        image = image/255.\n",
        "        image = np.expand_dims(image, axis=2)\n",
        "        X_test.append(image)\n",
        "        with open(os.path.join(labels_path,filename+\".txt\"), \"r\") as label_file:\n",
        "          # print(label_file)\n",
        "          for label in label_file:\n",
        "          # label = label_file[0].strip()\n",
        "            y_test.append(label)\n",
        "            max_len_label = max(max_len_label,len(label))\n",
        "\n",
        "label_files = []    ## stopping RAM from exploding\n",
        "\n",
        "# with open(\"/content/test_set.txt\", \"r\") as file:\n",
        "#   for value in file:\n",
        "#     value = value.split(\".\")[0]\n",
        "#     for filename in os.listdir():\n",
        "#       if(filename == \"InkData_word_processed_resized\"):\n",
        "#         continue\n",
        "#       filename = filename.split(\".\")\n",
        "#       if filename[1] == \"png\" and value in filename[0]:\n",
        "#         image = Image.open(filename[0]+\".png\")\n",
        "#         image = pil_resize(image)\n",
        "#         image = cv2.resize(image, (128,32))\n",
        "#         image = image/255.\n",
        "#         image = np.expand_dims(image, axis=2)\n",
        "        \n",
        "#         X_test.append(image)\n",
        "#         with open(filename[0]+\".txt\", \"r\") as label_file:\n",
        "#           for label in label_file:\n",
        "#             y_test.append(label)\n",
        "#             max_len_label = max(max_len_label,len(label))\n",
        "\n",
        "# with open(\"/content/validation_set.txt\", \"r\") as file:\n",
        "#   for value in file:\n",
        "#     value = value.split(\".\")[0]\n",
        "#     for filename in os.listdir():\n",
        "#       if(filename == \"InkData_word_processed_resized\"):\n",
        "#         continue\n",
        "#       filename = filename.split(\".\")\n",
        "#       if filename[1] == \"png\" and value in filename[0]:\n",
        "#         image = Image.open(filename[0]+\".png\")\n",
        "#         image = pil_resize(image)\n",
        "#         image = cv2.resize(image, (128,32))\n",
        "#         image = image/255.\n",
        "#         image = np.expand_dims(image, axis=2)\n",
        "#         X_valid.append(image)\n",
        "#         with open(filename[0]+\".txt\", \"r\") as label_file:\n",
        "#           for label in label_file:\n",
        "#             y_valid.append(label)\n",
        "#             y_valid_enc.append(encode_to_labels(label))\n",
        "#             y_valid_len.append(len(label))\n",
        "#             valid_input_len.append(31)\n",
        "#             max_len_label = max(max_len_label,len(label))\n",
        "\n",
        "# print(max_len_label, len(y_train), len(y_valid), len(y_test))\n",
        "# print(y_valid[:5])"
      ],
      "metadata": {
        "id": "vxvU4ajyM3S7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Dataset\n",
        "\n",
        "If following the pre-defined split above, jump to next section."
      ],
      "metadata": {
        "id": "EVn8RPiCur_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = \"/content/drive/MyDrive/Kaggle/vietnamese_handwritten_ocr/aug_word_data4.csv\"\n",
        "vn_df = pd.read_csv(data_file)"
      ],
      "metadata": {
        "id": "dSGG5wVNt4ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vn_df.iloc[0][0])\n",
        "img1 = np.array(vn_df.iloc[0][1].split(\" \"), dtype = float)#np.array([float(x) for x in vn_df.iloc[0][1].split(\" \")])\n",
        "img1 = img1.reshape(128, 32)\n",
        "print(np.histogram(img1))\n",
        "plt.hist(img1)\n",
        "plt.show()\n",
        "print((img1.T + -1*np.min(img1))*50)\n",
        "cv2_imshow((img1.T + -1*np.min(img1))*50)\n",
        "print(((img1.T+-1*np.min(img1))/(-1*np.min(img1))))\n",
        "# cv2_imshow(((img1.T+-1*np.min(img1))/(-1*np.min(img1)))*255)\n",
        "cv2_imshow(((img1.T/(-1*np.min(img1)))+1)*255)\n",
        "img1 = (img1.T/(-1*np.min(img1))+1)*255\n",
        "# plt.imshow(np.asarray(pd.to_numeric(vn_df.iloc[0][1])))\n",
        "plt.imshow(img1/255.)\n",
        "# plt.show()\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "gzFO8YwWt7bq",
        "outputId": "e4b61069-ef60-4523-c8ad-892f0ba2763d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bản\n",
            "(array([ 190,    0,   45,    0,   13,    0,   21,    0,   24, 3803]), array([-5. , -4.5, -4. , -3.5, -3. , -2.5, -2. , -1.5, -1. , -0.5,  0. ]))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[250. 250. 250. ... 250. 250. 250.]\n",
            " [250. 250. 250. ... 250. 250. 250.]\n",
            " [250. 250. 250. ... 250. 250. 250.]\n",
            " ...\n",
            " [  0.   0.   0. ... 250. 250. 250.]\n",
            " [250. 250. 250. ... 250. 250. 250.]\n",
            " [250. 250. 250. ... 250. 250. 250.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x32 at 0x7F0E1C14B4D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAAAAAD/SS/5AAABoElEQVR4nMWXPZKEIBCFPy2rD0TEgYg8EBEHMuJAHW0guOIMOFvgzouE6rIfzesfJqWFNbCZpkUvpjaB57H8zVxAi2U3/xkg2ryMt/6RXpclFoDk30YAs9Wt9ULAuG4CU/qnguANceUmrDJWNTOA84A4dcY4VdMMsvih/nMWhGDC78kah7RxcNpMumu5kLelpoPh/pmzqrZTBtRl6IaXjRl2JRu1N6aQbQcT8Lofy6x5U8b7qSKXYtFDe/J0+S8wn74VQATWivGTBFxIH4ZzaX4eRze0pfTF/5MOjiu4tKFtvd5DvPShdUyYjgi8VL/rRrkOxLgBhNhXm+sEQusOhJwqcte8blAfSK7+RYmk/LRoYnwzQNxjvjdJ/n0eGICjI4jtDMCZQPMwKw5yAEQBbyGg6vtGpLoGYlEORQHZp6WUopKuQboK56dZsLviRAPR1La7ZqSaBqxcjxVBiVhxuWRJbIyPn2KJ7+Jnt5fBQ1DQMulSBdhsB5Geh8nB/VsEhmDB0prBHsf0dtds+alwgl4fRYd6fEcefv0KPi7FT+EH7yiG4nYyFIwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x32 at 0x7F0E1BBF2090>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAAAAAD/SS/5AAABlElEQVR4nM2XWZLDIAxEH645EeRM+Ez4TCZX6vlgKS+xnQQmmf5IZAojIdSijU7hYT6f0Qojvouf16Yb0OqxOf4BILryGC/9Y1pdbiBJ6VcWAHtxaCxsG/rUQEqsITjiyEVae1eNJPmAhC/b4iRg0b7p9XrpL1jPbvARzqN7A0apllfl7Q6L0d1703YoZT0vnB5zYezfNiQPEqvEXzGhIwYIStuyYwnKjIfxdkchlVG1DbM7eaMzhoUtAGPAf85/DcBP2bDA/YMZqJW3qbve/eYQ7IyEuTbGOrKZ4/tQpXb2XYvfDqyfJ+IcAaYY+hzBrsWengFVKS2WeAvHgmRLBSMiuTodyhm5EBDXGK6nZP8BbsVdvRHM7er2fiGA082MeCgJMAKCgwkpNEqkwxpYq+GknFLhZ4qW66NNNz/LgqycBBgb81C+tts00kEG7EYbojlt1tYGUV9uokHN32oVu1uUIl9ZDGWmzi0tqSV9Vc27BjL+gy8jR4d28j4ek9jG8qmwgLaTbTGmhuv760fwdCv+K/wCxo13w1offPsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f0e1bb5ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vn_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "NyUAxSdSfNbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "images = []\n",
        "\n",
        "for i in range(len(vn_df)):\n",
        "  label = vn_df.iloc[i][0].strip()\n",
        "  max_len_label = max(len(label), max_len_label)\n",
        "  labels.append(label)\n",
        "  img1 = np.array(vn_df.iloc[i][1].split(\" \"), dtype = float)\n",
        "  img1 = img1.reshape(128, 32)\n",
        "  img1 = img1.T/(-1*np.min(img1))+1    ## reverse-standardized and standardized again to suit the problem\n",
        "  img1 = np.expand_dims(img1, axis=2)\n",
        "  images.append(img1)\n",
        "\n",
        "print(np.asarray(images).shape, np.asarray(labels).shape)\n",
        "print(max_len_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut7haXZUfeNU",
        "outputId": "344f51c1-07e3-4d2b-ddc7-c2f5065192f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(110734, 32, 128, 1) (110734,)\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Test Split"
      ],
      "metadata": {
        "id": "FrAenBbxWlQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(images, labels, train_size= 0.90, shuffle = True)\n",
        "print(len(X_train), len(y_train), len(X_valid), len(y_valid))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, train_size= 0.80, shuffle = True)\n",
        "\n",
        "images = []\n",
        "labels = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mod5FaV2WkFk",
        "outputId": "86c786e2-5d41-47fe-cac4-ec2607ff67ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99660 99660 11074 11074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid_enc = []\n",
        "valid_input_len = []\n",
        "y_valid_len = []\n",
        "\n",
        "for value in y_valid:\n",
        "  y_valid_enc.append(encode_to_labels(value))\n",
        "  y_valid_len.append(len(value))\n",
        "  valid_input_len.append(31)\n",
        "\n",
        "print(y_valid[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUUJJhw8t-_l",
        "outputId": "ea9e4b2e-69aa-4dea-89a9-d9090946692d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['kế', 'Quảng', 'lâu', 'nước', 'tư']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_enc = []\n",
        "train_input_len = []\n",
        "y_train_len = []\n",
        "\n",
        "for value in y_train:\n",
        "  y_train_enc.append(encode_to_labels(value))\n",
        "  y_train_len.append(len(value))\n",
        "  train_input_len.append(31)\n",
        "\n",
        "print(y_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWgVjBwLvVA8",
        "outputId": "30f10a14-d394-4098-bac0-bc73b2855a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['khả', 'phòng', 'một', 'nhờ', 'bí']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_path = []\n",
        "# test_label = []\n",
        "# with open(\"/content/RWTH.iam_word_gt_final.test.thresh\") as test_list:\n",
        "#   for value in test_list:\n",
        "#     test_path.append(value.split(\",\")[0].strip()+\".png\")\n",
        "#     test_label.append(value.split(\" \",1)[1].strip())\n",
        "\n",
        "# # print(test_path)\n",
        "\n",
        "# max_len_label = max(max_len_label,len(max(test_label, key=len)))\n",
        "# # print(max_len_label)"
      ],
      "metadata": {
        "id": "_RH3gP5KvXHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding the input sequences"
      ],
      "metadata": {
        "id": "tpEWy0QlM5E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_padded = pad_sequences(y_train_enc, maxlen=max_len_label, padding='post', value = len(char_encoding))\n",
        "y_valid_padded = pad_sequences(y_valid_enc, maxlen=max_len_label, padding='post', value = len(char_encoding))"
      ],
      "metadata": {
        "id": "w9zWRgXd379N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(X_train[0]*255)\n",
        "print(y_train[0])\n",
        "\n",
        "cv2_imshow(X_valid[0]*255)\n",
        "print(y_valid[0])\n",
        "\n",
        "cv2_imshow(X_test[5]*255)\n",
        "print(y_test[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IqpD1JJyvZar",
        "outputId": "bc0fc08c-1ea7-4414-f9c0-7103deadeb1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F6586FEB6D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABg0lEQVR4nO1a0RLDIAgbu/3/L7sHb71eJyKBiR3mcVetJATUjkopj404PKMXkB2IAETkvo60UAuw2feFToDNvjuQErT7tiNe448SkQv1Fxsll1MhgBcujCfXY1SA31X/jh4ZxFA4YA4d57dkEGOorHtVfyP+Uo+AHgCDM8djDT2wNJUFaM4bHj+3pCgl4B6pdkAzztjgKwLfbglfEOCS/pzL6o+LtIoQwIErTsIiv6WUhHcVxpB7ApynzpzdIizMCA4AaksqE9jzUi5BqnfAq6EPsOH3BduEKxdahQEGjTsobHhznS6TaOF/ENMKZrHwwf74PJxg1X/axdj7IivA+i1XlftHtnLPR+2kPR0A1CtL5fk+DDZnU+k0biavdqW4ju4sa9pJmEtk7giCVZXBUS7xWr+IidbuAEg37W4Y40gc5bhbs25y7FnQJBe77KtyTrCjY6tY6HxrvO6f9rXA93p4oe8BLqxNyyeR8UEjLuSAuwC4mOntX7YAsdh/zg3GFiAYb/9cI0G0VFyZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bình\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F6586509090>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAAByUlEQVR4nO1Z264DIQiUk/7/L+95MLEGFRFhYbvOQ9O0q+IMN124risd+OHP24C34wjgjGcIAADeJljh423AHM9lv1hOFNroEQAAD20TsuVT40NvL++hGwFis+9RtKwyXS5uCsq85892D6PfpyiK2smwpHHECEAuT1i4485GoVBPy1E6VgQUi62d1GiVVtTp5IGK8Cr7+91RLpJaXRZinxlhUVIQv2qV55Oe8+7Ptpp5vgPdBZA5vlH6ls0sZj+5C8Cvt8mS+q5JXBeuYpc/6jvcUYB6q0Szv8qIFjiE1icVmXk+AiBO6TLoniRHUPGMW9tQ5PLMqhvzNkIrH960N2SuoOdZzq1msumWItsI6AbpKvviRe1mVjTbRADC0P2qtbN0+Y66xtEQNLbOnFrQFGDqIF7st0eN9kkAaMlFRavt92vQux7ZrCAAMzDL7aYgmzP/JehLlfwjG1py2+NVt3/z6YJkCREVg+kM3R3SyWRUeNJYfvTigb/c/slRktEEstPX+ksgIp14gIg8TtkY5bSRkXyKVl4dOJ1Io4EgV0CRw9XjD2AUuJJ0EuH+682ginDMO4AfA/VG7LB/AwK9knwnjgDOOAI44x+vV7M8wmufaAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bình\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65865090D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABrElEQVR4nO1Z27KDIAyEM/3/X6YPTBmG4JIocdHDPrUaQ8jmJsaUUtjg4Y9twH/HJoCMTQAZdxMQf/BexVX/RBAyILd9Px89yPthIgGmbaeUUkpOnsJz3T0pqEecMobGaNBjEvYzxtsMJT5sA2Yix/UKbtXjVQSsk4V6cJowtwSv0wAC8T2A5QVrmfJu2oQSxKrUtRPL73omliaVSjUkAAuAzd5EQG1f2dJwXgx2no7Udq/nJfKtHOa1TGMz0IztlJprOBIgnX7uWSymnDi71+tnuxw0yuVySgPuyAC5yYtF5v5eXa8oPSvt0SRxfuUEMjYCgEcm1nTTm5QmKgGXMuTB6vhuo1YpjwgwBbV1sj4yzm9C12u+yIGpeyECuIPKUDKbp0+CYHTNEZpKFUSGmfQz34S7vjtxjFPvvzi6G6dypuwuN7RB34qHGbPKUYQ+NoFnm78NK0fCWJUGV1KKTIAMXnm3XLcWkEVOezBmdjyn/gkYegSeUYIAHur3GoCD/VHeHTiANgFkzCTgBbXiHPB5Ne4Bq3wYegE0R36dpzYBXOweQMYmgIxNABlfbENrQUL/gJEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thương\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Architecture\n",
        "\n",
        "Based on [this](https://arxiv.org/pdf/1507.05717.pdf) paper and [this](https://theailearner.com/2019/05/29/creating-a-crnn-model-to-recognize-text-in-an-image-part-1/) blog."
      ],
      "metadata": {
        "id": "uWdR3eZe51eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input with shape of height=32 and width=128 \n",
        "inputs = Input(shape=(32,128,1))\n",
        " \n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        " \n",
        "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        " \n",
        "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        " \n",
        "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "# poolig layer with kernel size (2,1)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        " \n",
        "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        " \n",
        "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        " \n",
        "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        " \n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        " \n",
        "# bidirectional LSTM layers with units=256\n",
        "blstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.3))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.3))(blstm_1)\n",
        " \n",
        "outputs = Dense(len(char_encoding)+1, activation = 'softmax')(blstm_2)\n",
        "\n",
        "# model to be used at test time\n",
        "act_model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "gKnkuliekHbm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_model.summary()"
      ],
      "metadata": {
        "id": "uG0cubQcgb7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055a9078-754a-4fc8-a70c-aaa6e3661cfc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 128, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 128, 64)       640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 64, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 64, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 32, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 32, 256)        295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 32, 256)        590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 32, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 32, 512)        1180160   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4, 32, 512)       2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 32, 512)        2359808   \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4, 32, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 32, 512)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 1, 31, 512)        1049088   \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 31, 512)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 31, 512)          1574912   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 31, 512)          1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 31, 148)           75924     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,778,644\n",
            "Trainable params: 8,776,596\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTC Loss function"
      ],
      "metadata": {
        "id": "aah-qIWN0AP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = Input(name='the_labels', shape=[max_len_label], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        " \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
      ],
      "metadata": {
        "id": "Sxm3Z40EM9qE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation"
      ],
      "metadata": {
        "id": "58ijorYB0E3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
        " \n",
        "# filepath=\"best_model.hdf5\"\n",
        "filepath = \"/content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "q3sFjkN_Oaq9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "train_input_len = np.array(train_input_len)\n",
        "y_train_len = np.array(y_train_len)\n",
        "\n",
        "X_valid = np.array(X_valid)\n",
        "valid_input_len = np.array(valid_input_len)\n",
        "y_valid_len = np.array(y_valid_len)"
      ],
      "metadata": {
        "id": "a4FUS9W5ObeY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "zN2f9BrFawoQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_initial(model,_epochs=10, _batch_size=64):\n",
        "  model.fit(x=[X_train, y_train_padded, train_input_len, y_train_len], y=np.zeros(len(train_input_len)), batch_size=_batch_size, epochs = _epochs, validation_data = ([X_valid, y_valid_padded, valid_input_len, y_valid_len], [np.zeros(len(valid_input_len))]), verbose = 1, callbacks = callbacks_list)\n",
        "\n",
        "def continue_training(model):\n",
        "  model.load_weights(\"/content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\")\n",
        "  train_initial(model)\n",
        "\n",
        "def transfer_learning(model,epochs=10, batch_size=64):\n",
        "  model.load_weights(\"/content/drive/MyDrive/IAM_dataset/best_model_binarized_256.hdf5\", by_name=True, skip_mismatch=True)\n",
        "  train_initial(model, _epochs=epochs, _batch_size=batch_size)"
      ],
      "metadata": {
        "id": "z77bdpStOdOp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer_learning(model, epochs=20, batch_size=64)\n",
        "train_initial(model, _epochs=20, _batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsFE3ua2kHdU",
        "outputId": "2a833d95-09ee-4ee0-a522-c5bc38c02ab0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 9.0431\n",
            "Epoch 1: val_loss improved from inf to 6.08600, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 135s 109ms/step - loss: 9.0431 - val_loss: 6.0860\n",
            "Epoch 2/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 3.5078\n",
            "Epoch 2: val_loss improved from 6.08600 to 2.96046, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 111s 106ms/step - loss: 3.5078 - val_loss: 2.9605\n",
            "Epoch 3/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 2.2017\n",
            "Epoch 3: val_loss improved from 2.96046 to 2.44114, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 111s 106ms/step - loss: 2.2017 - val_loss: 2.4411\n",
            "Epoch 4/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.7106\n",
            "Epoch 4: val_loss improved from 2.44114 to 1.85928, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 109s 104ms/step - loss: 1.7106 - val_loss: 1.8593\n",
            "Epoch 5/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.4483\n",
            "Epoch 5: val_loss improved from 1.85928 to 1.80678, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 109s 104ms/step - loss: 1.4483 - val_loss: 1.8068\n",
            "Epoch 6/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.2999\n",
            "Epoch 6: val_loss improved from 1.80678 to 1.55344, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 108s 103ms/step - loss: 1.2999 - val_loss: 1.5534\n",
            "Epoch 7/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.1605\n",
            "Epoch 7: val_loss improved from 1.55344 to 1.42129, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 109s 104ms/step - loss: 1.1605 - val_loss: 1.4213\n",
            "Epoch 8/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.0819\n",
            "Epoch 8: val_loss did not improve from 1.42129\n",
            "1047/1047 [==============================] - 105s 101ms/step - loss: 1.0819 - val_loss: 1.5568\n",
            "Epoch 9/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 1.0186\n",
            "Epoch 9: val_loss improved from 1.42129 to 1.34798, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 108s 103ms/step - loss: 1.0186 - val_loss: 1.3480\n",
            "Epoch 10/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.9483\n",
            "Epoch 10: val_loss did not improve from 1.34798\n",
            "1047/1047 [==============================] - 104s 100ms/step - loss: 0.9483 - val_loss: 1.5642\n",
            "Epoch 11/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.8992\n",
            "Epoch 11: val_loss improved from 1.34798 to 1.30066, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 107s 102ms/step - loss: 0.8992 - val_loss: 1.3007\n",
            "Epoch 12/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.8633\n",
            "Epoch 12: val_loss improved from 1.30066 to 1.22389, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 107s 102ms/step - loss: 0.8633 - val_loss: 1.2239\n",
            "Epoch 13/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.8326\n",
            "Epoch 13: val_loss improved from 1.22389 to 1.21871, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 107s 102ms/step - loss: 0.8326 - val_loss: 1.2187\n",
            "Epoch 14/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.7987\n",
            "Epoch 14: val_loss did not improve from 1.21871\n",
            "1047/1047 [==============================] - 105s 100ms/step - loss: 0.7987 - val_loss: 1.2611\n",
            "Epoch 15/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.7533\n",
            "Epoch 15: val_loss did not improve from 1.21871\n",
            "1047/1047 [==============================] - 105s 100ms/step - loss: 0.7533 - val_loss: 1.3182\n",
            "Epoch 16/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.7315\n",
            "Epoch 16: val_loss did not improve from 1.21871\n",
            "1047/1047 [==============================] - 104s 99ms/step - loss: 0.7315 - val_loss: 1.2242\n",
            "Epoch 17/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.7172\n",
            "Epoch 17: val_loss improved from 1.21871 to 1.10204, saving model to /content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\n",
            "1047/1047 [==============================] - 105s 100ms/step - loss: 0.7172 - val_loss: 1.1020\n",
            "Epoch 18/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.7033\n",
            "Epoch 18: val_loss did not improve from 1.10204\n",
            "1047/1047 [==============================] - 103s 99ms/step - loss: 0.7033 - val_loss: 1.1527\n",
            "Epoch 19/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.6551\n",
            "Epoch 19: val_loss did not improve from 1.10204\n",
            "1047/1047 [==============================] - 106s 101ms/step - loss: 0.6551 - val_loss: 1.1605\n",
            "Epoch 20/20\n",
            "1047/1047 [==============================] - ETA: 0s - loss: 0.6619\n",
            "Epoch 20: val_loss did not improve from 1.10204\n",
            "1047/1047 [==============================] - 109s 104ms/step - loss: 0.6619 - val_loss: 1.2423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NgDcSxTkvVQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -aux|grep python"
      ],
      "metadata": {
        "id": "fORfLt7Pvkzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## reducing RAM (colab issues)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_valid = []\n",
        "y_valid = []"
      ],
      "metadata": {
        "id": "BJA6I-rqU1Nv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "F6OaGzJw0Lzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "act_model.load_weights(\"/content/drive/MyDrive/Kaggle/vn_best_model_binarized_256.hdf5\")\n",
        "\n",
        "prediction = act_model.predict(X_test)\n",
        "\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],greedy=True)[0][0])\n",
        "\n",
        "predicted_labels = [\"\".join([char_encoding[x] for x in img if x != -1]) for img in out]\n",
        "# print([\"\".join([char_encoding[x] for x in img if x != -1]) for img in out])\n",
        "# print(predicted_labels[:10])"
      ],
      "metadata": {
        "id": "Gy7CiKAVOkHb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  cv2_imshow(X_test[i]*255)\n",
        "  print(y_test[i])\n",
        "  print(predicted_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Twv1NTikvj5N",
        "outputId": "bee7b514-9a84-4554-900a-21647637d4e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F6583FCE5D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABd0lEQVR4nO1ayxLDIAgsnf7/L9NDZpyMD0SNLK3ssY0EdwkCCTHzK4DDG+3A6figHbADEVV/x+YAihSUCWNMSAhQAZEdLXEGVGAZlCEAGCEAGCEAGCEAGCEAGKcIQEStRgyLUwRgZmZ2qEG/4xCcPqqJ29SdSbOgRH3rxndtVpwrNd4qrWWj20V/GCf4mv3VFax1cXn9kKndWElc11phF09OQ9NtZPq6PmWm9BpoLOtR8q5XIvnQPXia23skBktGJjgaWtIVTGkts6OPg9H81qyCLiuL0VStPYBZJbHficoaiZrwnzhdpDJ0E1P6BzkV73pPBHIzU0OZXXmqTTC2/Y1YNfw1m09Pz+iuqqsy9u9ulPaTigYP696CbL3gm7agz3sC16N19swJ56HOE2AWiQ9iSDaPAkxXIL8IF19F+CmT7IEUwFW7iwJ4GlqdQ5RwOMV8CmABlPWogScoIFNQ1hNoZq7/B18Fhs+vB7fClwAH4pRXkm7xBRF7Cx2b87WQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "người\n",
            "người\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F6584241E10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABaElEQVR4nO2a0RbCIAiGR6f3f2W78BxacyIyk3+T76rTioB/iMMopbQFfry8HVidt7cDX4iIX69TlygCENE6Sd+DFfa+CLY16gBLgAMHPTLIDhuQBIBdFk6FYTB9rlFNMQd5r3i2ljwZnKCkJpy9hK2DGkpvQdY3lF3QfEDuKulBLN8jII4+laoAkfc5xCjCmRDAmRDAmRDAmRDAmRDAmRDAGSABiEgzxnkYbqOIcvTPj373nQMacBCgOeE4KDFEBtixSmPSOXYUasjCKAe6qmrmwdy8CuhN5dh+kFJSOlB+7K8D+XYTHpIIkEMFOZa8Cyj9zOJpjDN6lxoCuGSNE8EnQkPMaqzV4pU12Duc0ctgrMpeNBaEZdq2Lzr90dqbGuN6gx02uw7wzDKcZtDQ67qqQTjuLt3Q5+HwXflfDU3LlxpjuXMvLwlGHLsCJ+7Kxszc1X+uIvRGL8xL68gHlJUFQABoFrQmH+7C/ykewAPbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "làm\n",
            "làm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABcklEQVR4nO1aQRLDIAgMnf7/y/TgjE3VEEAiSWFPPYjdsKJLDCDilvDDy5tAdLy9CbAAAPX3n5UsPOt5ihIznPdaTk5lgmdUQIVJvvaTVD28lHhYBczjKOPztaXkE00AGgCrE5Iu6AeICADNOXEpUoAWiFhkWPN3KcAYyzYiMwFWlu0/gbKhRE57C2HizQM6AmXi+NowpypR602IO5SNWNPLDD31xhaDnm0Ipm3vF8rdBJ7thIelwMxLbzaY9uNUJGIFSIvs6gbN4FWEjlyNasIVi7ofcCqPiDN/sEIth3dB836JeELO5MwE6XhKl6OBDVUQnaxoXWpKi8s8YMpI0dovrKTcDFxH4cqv6zpS7XnowH4f4OwMxJUDEd4fNtJdyMb2iVI5LwAnVroSdWfPURT/1sHHd5tYC8NexBHhGp+7IV/GOSMFcEYK4IwUwBkpgDOCCtBYWMfbpKACrL98P0L0PsDrc6AvgeACuCPoFnQffADqXvMmdxEAkAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "triệu\n",
            "triệu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB690>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABP0lEQVR4nO2Z0Q7DIAhFy7L//+XuoYnpahW0cFHLeVuzzHovoDDa930L/Ph4v8Db+Qq/R0Tnj5E3WogMIKKL4vmToA++BF1in30eNMEYcKgcwW4HnwGhvik1AypFJlzRgsmAitDhgQpFA+KMxRCNmDNhgDNFA6LEY5COIhbg9lRzj7MFDSgJfau1uyu1kc4sbbDioBDf+jAztWGHbmelrKT5j7+SNw9X5/UdzQNkXkrWeph/InFH8CDtE1qg2zfemprSBRw9mOUoypEETYOsLkLMq36ivoWGTvj4CeSMaAH1N+792/qA5AFMlNnVZ2OoU0pMbM6bAfIrw6NYBgg0kQd9rYlCMYHZYL2KHMUBhlo1x2iU7xy8nPqiyscpPlRNb2WAXVjdZ4ROjFZb8JhfKOsR+lrdE/5DnpcT/wk78wNk/tsAMymPkAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lo\n",
            "lo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB490>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABXUlEQVR4nO2a2w7CMAiGh/H9XxkvappmnRRaDm7luzJb7PD/ewAmIOKRxPGKDmB33tEBPAEA6C8yt5Y0YJ6q+6XW5e7QBsgzwA6OB3kGBJMGWMHcgtIAE5jqH3kIq8OXvpAGqCGVvrCXAaeEvYjVXpzLCeek/37XLQ2ls2a3ABSfrvKLXOsAAEBEdSFuja0BlzV6JT04aANo+Yb8GrldB4rD3pSYVsT6ufcYYgqxVvTFdXZ3wiphRNx87heCWxF9Jr4b8b2gzT3QOYQt5NPaoKSxOW+MkwZc1vSTETR12alGm0uWVlIs/yJRZoBFO6GUBf1T+kcM1VmUL6RE5xpgFFyv/vAWEQkxGhFA/WwkPR0VK2IL9TljSpcCf8yKw3zXMUC9ibi48oiZS/ecfXYY/sJyXQEhHWlRFkRseiIEKYPDGRD+JuCfscqCst3GRKcOOJGK88l/xgUT3wvanA8MuQgMZsFNIwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "để\n",
            "để\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB450>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABrElEQVR4nO1Z27KDIAyEM/3/X6YPTBmG4JIocdHDPrUaQ8jmJsaUUtjg4Y9twH/HJoCMTQAZdxMQf/BexVX/RBAyILd9Px89yPthIgGmbaeUUkpOnsJz3T0pqEecMobGaNBjEvYzxtsMJT5sA2Yix/UKbtXjVQSsk4V6cJowtwSv0wAC8T2A5QVrmfJu2oQSxKrUtRPL73omliaVSjUkAAuAzd5EQG1f2dJwXgx2no7Udq/nJfKtHOa1TGMz0IztlJprOBIgnX7uWSymnDi71+tnuxw0yuVySgPuyAC5yYtF5v5eXa8oPSvt0SRxfuUEMjYCgEcm1nTTm5QmKgGXMuTB6vhuo1YpjwgwBbV1sj4yzm9C12u+yIGpeyECuIPKUDKbp0+CYHTNEZpKFUSGmfQz34S7vjtxjFPvvzi6G6dypuwuN7RB34qHGbPKUYQ+NoFnm78NK0fCWJUGV1KKTIAMXnm3XLcWkEVOezBmdjyn/gkYegSeUYIAHur3GoCD/VHeHTiANgFkzCTgBbXiHPB5Ne4Bq3wYegE0R36dpzYBXOweQMYmgIxNABlfbENrQUL/gJEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thương\n",
            "thương\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB890>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABV0lEQVR4nO2a2xKDIAxEodP//+X0gRllFEPCxQ0057EyAXdDiNpIRMHB8UEv4N/5ohcwhRhj8XeD2z0aXFMbh+jMHaUxpm55BwO0spqyYfkzoEFNI9InljegmadzQhukM87yBrSlMxEN3Ac9HixvQICWlGPqZg92OITh9HS9ez4HvMNd96S4ajdwO0DSWf8PF1mLmjS0ZI87II81vHE21YnzqLKQiLSHQWUHVGfN5xMKeoRdyAYVEt3OwfxQPtblalXQ4oCpNgjzcfjscg9EOf5U71R1kBF6UoljlpEzz3tJZNmgWyxesvtVYTUbogUTp3hp1LzF6ULNYPFOyVYpTNi240E+mAli58VcvSxr15qYenJ2tr+q/IC3ANafhJvrwyVdXiv9WqwbsD07vIxbGjcAjBsAxg0A4waAcQPAuAFg3ICTIf+T0OKfJEOAvpbwJ2EwXoLA/AAMwPAUf2l4lQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "một\n",
            "một\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB8D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABIUlEQVR4nO2a3Q7CMAiFxfj+r4wXS5bF1fFfpj3f9SyFA2thEjM/QB/P7g2sjkcAIiKi9K2sycv09BZ3vLUSMQhARAh9OioBkPh1yGcAol+K6hBG9OsQBMBtpxq5ApD+paARa0a+Wbpvn5rX18+V17VTDndUAjiWVv7q6M9NxLgIcYU7qux2aOCom0Yxck2bwqUN075F/fNuT6y23GQZ+igaW6Za81pvIz66KB1+BBtMsWiUsbIN47a19mlodYYy82378KwthVJMjE5KCk+og414KI4knwEa2+elUvJ3ZhH4Ov+QcomODZVI1OC8+B9QVd2Ri8FS4BtLM5gFNQMBmoEAzUCAZiBAMxCgGQjwlTnfwyHAmGn/QoMAY6b1pxCgmTds+rca95rX0QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "họ\n",
            "họ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB810>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABjElEQVR4nO1Z0RLDIAjT3f7/l9lDd66nE0OnDWvJ0+5GkRIiaLOIpAAPD3YAd0cQQEYQ8EHO+fxFg4A3cs6UdkgmgFJ0rsAkgFV0LYiRMAkQkVBA9ACyEO9OAF2CT+La616+eNZLezPj9qEBAavluch5catz7GEEGCsArCaf8B+zRkClUD9T45VgaMLb1EjvWhdDl4Cv9S4iMbzPxZExNKQwEV0C9O2eJYXrEf/TOaBwcKA5W1v6fqFzBrNzVvn1IFYysi7KluN2zN//i9dEL2zr+LcXpTUPc07CVinghOmWVY4qlRzTZWreYvOMUNXzoGDaVcR+c8DrRQeeRCVHOKy567GVLJEPDmLWV9L3aHxXteoJN1acDOumqnRdmmD2llzG9a5iViT0nOxXIx+SXJCDtbehs3ZhxVixBGvwwDxm2hjL7682Hr8HgFkD+3Ox7/nBAxsuOgyjBfN7QAt84EOyAB4V8XJGzKwP+rrg1Ke99A/Xy1b4IiB19gRvQU6EOwLuBo9N+FYIAsh4AUX4QS6T+TYOAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Năm\n",
            "Năm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x32 at 0x7F65840AB950>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAAgCAIAAABVQOdyAAABQUlEQVR4nO2a3Q7CIAxGW+P7v/K8ICEGN1b6Q2F+51K3Cj0VC5OP4yCQxyt7AP8OBITDzJ13ISAZCIilX/5E9J4zjkXopMO9Gamf1Y/M6IIqV3rkKWoiSG6EgHtul5GKIpkQkAx+hJOBgGQgIBkISAYCktl1I9ZvDTdq7bYRoNjjKMI2TBC5gQDhnn40mjDmr6HTW8plihGuK8A376TNUbleuBlmHt7YLifAPe9kKM9K3Fp0KUB+ACJBdCxlTpNxAMb4ivKnjoASsXlFM7Q7Ikp+PmUWzktQE8vdR2jJz6ROhJlHHehPQ9U+5pd8nGl7ZLfjaImP3NXGUYPjRKKeB5z+hq+w2lhy9z0pt8INTUpTdPZnfo4o2ryQRWyF3sbS8q7wrbLgL+AZbeU0PHfCSL0CNwGPaeong39FJIMnYsl8AIjMvSio4cp1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xã\n",
            "xã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Accuracy and CER"
      ],
      "metadata": {
        "id": "ZKWhTCjXeqIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsf04SbXu_Md",
        "outputId": "76356c14-8c21-44c4-9126-24b782cf4aa4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149856 sha256=d2393be0b5a9daf2c4ae512282ec2b03f712f892feea94ed1f1478364a9f2c60\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cer = fastwer.score(test_label, predicted_labels , char_level=True)\n",
        "\n",
        "from Levenshtein import distance\n",
        "\n",
        "cer_each = []\n",
        "\n",
        "# edit_distances_N = [distance(test_label[i], predicted_labels[i])/len(test_label[i]) for i in range(len(test_label))]    ## Need to calculate CER better.. edit_distance/(edit_distance+correct)\n",
        "for i in range(len(y_test)):\n",
        "  edit_dist = distance(y_test[i], predicted_labels[i])\n",
        "  cer_each.append(edit_dist/(edit_dist+max(0,len(y_test[i])-edit_dist)))\n",
        "\n",
        "# edit_distances_N = [distance(test_label[i], predicted_labels[i])/(distance(test_label[i], predicted_labels[i])+max(0,len(test_label[i])-distance(test_label[i], predicted_labels[i]))) for i in range(len(test_label))]\n",
        "avg_cer = np.sum(cer_each)/len(cer_each)\n",
        "print(\"Average CER:\", avg_cer)\n",
        "\n",
        "accuracy = np.sum(np.asarray(y_test) == np.asarray(predicted_labels))/len(y_test)\n",
        "# print(np.sum(np.asarray(y_test) == np.asarray(predicted_labels)))\n",
        "print(\"Accuracy: \", accuracy)#np.sum(np.asarray(y_test) == np.asarray(predicted_labels))/len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Aqb5hD-hiSq",
        "outputId": "91ff8a9a-7c6e-4adb-e881-9196ceb9b86b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average CER: 0.08919250811347168\n",
            "Accuracy:  0.7904439577941469\n"
          ]
        }
      ]
    }
  ]
}